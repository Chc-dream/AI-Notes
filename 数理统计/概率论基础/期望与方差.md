# 期望与方差

# 期望

期望描述了随机变量的平均情况，衡量了随机变量 $X$ 的均值，它是概率分布的泛函。离散型随机变量 $X$ 的期望如下：

$$
\mathbb{E}[X]=\sum_{i=1}^{\infty} x_{i} p_{i}
$$

若右侧级数不收敛，则期望不存在。连续性随机变量 $X$ 的期望如下：

$$
\mathbb{E}[X]=\int_{-\infty}^{\infty} x p(x) d x
$$

若右侧极限不收敛，则期望不存在。

## 期望的性质

常数的期望就是常数本身，对常数 $C$ 有：

$$
\mathbb{E}[C X]=C \mathbb{E}[X]
$$

对两个随机变量 $X,Y$，存在：

$$
\mathbb{E}[X+Y]=\mathbb{E}[X]+\mathbb{E}[Y]
$$

该结论可以推广到任意有限个随机变量之和的情况。对两个相互独立的随机变量，有：

$$
\mathbb{E}[X Y]=\mathbb{E}[X] \mathbb{E}[Y]
$$

该结论可以推广到任意有限个相互独立的随机变量之积的情况。

## 复合函数期望

对于随机变量 $X$ ，设 $Y=g(X)$ 也为随机变量，$g(\cdot)$ 是连续函数。

若 $X$ 为离散型随机变量，且 $Y$ 的期望存在，则：

$$
\mathbb{E}[Y]=\mathbb{E}[g(X)]=\sum_{i=1}^{\infty} g\left(x_{i}\right) p_{i}
$$

也记作：

$$
\mathbb{E}_{X \sim P(X)}[g(X)]=\sum_{x} g(x) p(x)
$$

同样，若 $X$ 为连续型随机变量，且 $Y$ 的期望存在，则：

$$
\mathbb{E}[Y]=\mathbb{E}[g(X)]=\int_{-\infty}^{\infty} g(x) p(x) d x
$$

也记作：

$$
\mathbb{E}_{X \sim P(X)}[g(X)]=\int g(x) p(x) d x
$$

该定理的意义在于：当求 $\mathbb{E}(Y)$ 时，不必计算出 $Y$ 的分布，只需要利用 $X$ 的分布即可。该定理可以推广至两个或两个以上随机变量的情况，对于随机变量 $X, Y$，假设 $Z=g(X, Y)$ 也是随机变量，$g(\cdot)$ 是连续函数，则有：

$$
\mathbb{E}[Z]=\mathbb{E}[g(X, Y)]=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} g(x, y) p(x, y) d x d y
$$

也记作：

$$
\mathbb{E}_{X, Y \sim P(X, Y)}\left[g(X, Y) \int g(x, y) p(x, y) d x d y\right.
$$

# 方差

## 方差的性质

# 协方差

## 相关系数

# 协方差矩阵
